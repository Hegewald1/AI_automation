{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "63341367",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text analysis basics in Python\n",
    "# Bigram/trigrams and topic modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1461cae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus = [\n",
    "# 'Great course. Love the professor.',\n",
    "# 'Great content. Textbook was great',\n",
    "# 'This course has very hard assignments. Great content.',\n",
    "# 'Love the professor.',\n",
    "# 'Hard assignments though',\n",
    "# 'Hard to understand.'\n",
    "# ]\n",
    "corpus = [\n",
    "'Good nachos. Love the cheese',\n",
    "'Great texture. Nice and crispy',\n",
    "'The olives on the nachos were nasty',\n",
    "'Loved the salsa though.',\n",
    "'Very expensive,'\n",
    "'Very delicious'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ea737907",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(corpus)\n",
    "df.columns = ['reviews']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0d01c6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next, we can explore some word associations. N-grams analyses are often used to see which words often show up together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1275d759",
   "metadata": {},
   "outputs": [],
   "source": [
    "#An n-gram is a contiguous sequence of n items from a given sample of text or speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3674e609",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stoplist = stopwords.words('english') + ['though']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3def1f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we can remove the stop words and work with some bigrams/trigrams. \n",
    "#The function CountVectorizer “convert a collection of text documents to a matrix of token counts”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4321da18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "c_vec = CountVectorizer(stop_words=stoplist, ngram_range=(2,3))\n",
    "# matrix of ngrams\n",
    "ngrams = c_vec.fit_transform(df['reviews'])\n",
    "# count frequency of ngrams\n",
    "count_values = ngrams.toarray().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "320db383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of ngrams\n",
    "vocab = c_vec.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5ee7b577",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ngram = pd.DataFrame(sorted([(count_values[i],k) for k,i in vocab.items()], reverse=True)\n",
    "            ).rename(columns={0: 'frequency', 1:'bigram/trigram'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "be127c10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frequency</th>\n",
       "      <th>bigram/trigram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>texture nice crispy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>texture nice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>olives nachos nasty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>olives nachos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>nice crispy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>nachos nasty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>nachos love cheese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>nachos love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>loved salsa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>love cheese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>great texture nice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>great texture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>good nachos love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>good nachos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>expensive delicious</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    frequency       bigram/trigram\n",
       "0           1  texture nice crispy\n",
       "1           1         texture nice\n",
       "2           1  olives nachos nasty\n",
       "3           1        olives nachos\n",
       "4           1          nice crispy\n",
       "5           1         nachos nasty\n",
       "6           1   nachos love cheese\n",
       "7           1          nachos love\n",
       "8           1          loved salsa\n",
       "9           1          love cheese\n",
       "10          1   great texture nice\n",
       "11          1        great texture\n",
       "12          1     good nachos love\n",
       "13          1          good nachos\n",
       "14          1  expensive delicious"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b7bc8957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-Negative Matrix Factorization (NMF) is a matrix decomposition method\n",
    "# we can use to produce 3 topics and we showed 3 bigrams/trigrams in each topic. \n",
    "# How it actually does it takes some math, but don't worry about the details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "89d9ff39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ac65310c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/madsh/Documents/EAA/AI_automation/venv/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:289: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidfvectorizer',\n",
       "                 TfidfVectorizer(ngram_range=(2, 3),\n",
       "                                 stop_words=['i', 'me', 'my', 'myself', 'we',\n",
       "                                             'our', 'ours', 'ourselves', 'you',\n",
       "                                             \"you're\", \"you've\", \"you'll\",\n",
       "                                             \"you'd\", 'your', 'yours',\n",
       "                                             'yourself', 'yourselves', 'he',\n",
       "                                             'him', 'his', 'himself', 'she',\n",
       "                                             \"she's\", 'her', 'hers', 'herself',\n",
       "                                             'it', \"it's\", 'its', 'itself', ...])),\n",
       "                ('nmf', NMF(n_components=3))])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(stop_words=stoplist, ngram_range=(2,3))\n",
    "nmf = NMF(n_components=3)\n",
    "pipe = make_pipeline(tfidf_vectorizer, nmf)\n",
    "pipe.fit(df['reviews'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ec69bb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = \"Topic #%d: \" % topic_idx\n",
    "        message += \", \".join([feature_names[i]\n",
    "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e121eeeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0: loved salsa, olives nachos nasty, olives nachos\n",
      "Topic #1: texture nice crispy, texture nice, nice crispy\n",
      "Topic #2: expensive delicious, olives nachos nasty, olives nachos\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/madsh/Documents/EAA/AI_automation/venv/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "print_top_words(nmf, tfidf_vectorizer.get_feature_names(), n_top_words=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "275c22e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looks like topic 0 is about the professor and courses; \n",
    "#topic 1 is about the assignment,\n",
    "#and topic 3 is about the textbook. \n",
    "#Note that we do not know what is the best number of topics here. We used 3 just because our sample size is very small. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9f677b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LatentDirichletAllocation\n",
    "# It is a topic model that is used for discovering abstract topics from a collection of documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bc33dbef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidfvectorizer',\n",
       "                 TfidfVectorizer(ngram_range=(2, 3),\n",
       "                                 stop_words=['i', 'me', 'my', 'myself', 'we',\n",
       "                                             'our', 'ours', 'ourselves', 'you',\n",
       "                                             \"you're\", \"you've\", \"you'll\",\n",
       "                                             \"you'd\", 'your', 'yours',\n",
       "                                             'yourself', 'yourselves', 'he',\n",
       "                                             'him', 'his', 'himself', 'she',\n",
       "                                             \"she's\", 'her', 'hers', 'herself',\n",
       "                                             'it', \"it's\", 'its', 'itself', ...])),\n",
       "                ('latentdirichletallocation',\n",
       "                 LatentDirichletAllocation(n_components=3))])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words=stoplist, ngram_range=(2,3))\n",
    "lda = LatentDirichletAllocation(n_components=3)\n",
    "pipe = make_pipeline(tfidf_vectorizer, lda)\n",
    "pipe.fit(df['reviews'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0da8f51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = \"Topic #%d: \" % topic_idx\n",
    "        message += \", \".join([feature_names[i]\n",
    "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4fd0ff5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0: loved salsa, expensive delicious, texture nice\n",
      "Topic #1: olives nachos nasty, olives nachos, nachos nasty\n",
      "Topic #2: nachos love cheese, nachos love, love cheese\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_top_words(lda, tfidf_vectorizer.get_feature_names(), n_top_words=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d951fd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now you might try it out with another corpus..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d62c74f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
